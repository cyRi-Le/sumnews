(this.webpackJsonpsumnews=this.webpackJsonpsumnews||[]).push([[0],{38:function(e,t,n){},39:function(e,t,n){},40:function(e,t,n){},41:function(e,t,n){},48:function(e,t,n){},49:function(e,t,n){},50:function(e,t,n){},51:function(e,t,n){},52:function(e,t,n){},53:function(e,t,n){},73:function(e,t,n){},74:function(e,t,n){},75:function(e,t,n){"use strict";n.r(t);var s=n(1),a=n.n(s),c=n(30),i=n.n(c),r=(n(38),n(39),n(40),n(8)),l=n(9),o=n(11),d=n(10),j=(n(41),n(13)),h=n(0),m=function(e){Object(o.a)(n,e);var t=Object(d.a)(n);function n(){return Object(r.a)(this,n),t.apply(this,arguments)}return Object(l.a)(n,[{key:"render",value:function(){return Object(h.jsxs)("div",{className:"header-container flex-container flex-container-vertical",children:[Object(h.jsx)("div",{id:"logo-container",children:Object(h.jsxs)("ul",{className:"menu-nav",children:[Object(h.jsx)("li",{className:"content-padding-level3",children:Object(h.jsx)(j.b,{to:"/sample",children:"English results"})}),Object(h.jsx)("li",{className:"content-padding-level3",children:Object(h.jsx)(j.b,{to:"/example",children:"French results"})}),Object(h.jsx)("li",{className:"content-padding-level3",children:Object(h.jsx)(j.b,{to:"/home",children:"Home"})})]})}),Object(h.jsxs)("div",{id:"mid-top-wrapper",className:"center-content content-padding-level2",children:[Object(h.jsx)("h3",{children:"News Summarization using Transformers"}),Object(h.jsx)("h5",{children:"EPFL computer science semester project"})]})]})}}]),n}(a.a.Component),b=(n(48),function(e){Object(o.a)(n,e);var t=Object(d.a)(n);function n(){return Object(r.a)(this,n),t.apply(this,arguments)}return Object(l.a)(n,[{key:"render",value:function(){return Object(h.jsx)("div",{className:"footer-container center-content",children:Object(h.jsx)("h6",{children:"EPFL's MLO Lab"})})}}]),n}(a.a.Component)),u=(n(49),n(20));n(50);function O(e){return Object(h.jsx)("div",{className:"button-link-container",children:Object(h.jsx)("a",Object(u.a)(Object(u.a)({className:"button-link"},e),{},{children:e.children}))})}var p=function(e){Object(o.a)(n,e);var t=Object(d.a)(n);function n(e){var s;return Object(r.a)(this,n),s=t.call(this,e),document.title="News Summarization with Transformers",s}return Object(l.a)(n,[{key:"render",value:function(){return Object(h.jsx)("div",{className:"home-container",children:Object(h.jsxs)("div",{id:"presentation-wrapper",className:"flex-wrapper flex-wrapper-vertical content-padding-level5",children:[Object(h.jsxs)("div",{className:"section-wrapper",children:[Object(h.jsx)("div",{className:"title-wrapper",children:Object(h.jsx)("h4",{className:"content-padding-left-level4",children:"Project"})}),Object(h.jsx)("div",{className:"section-content",children:Object(h.jsx)("p",{children:"Summarization has become one of the most important task in Natural Language Processing. The state-of-the art Deep Learning models achieve outstanding quality summarization. All of the recent best performing models use the Transformer architecture introduced by Vaswani et al (2017). In this project, we use the DistilBart model, which is the distilled model (over CNN/Daily mail dataset) of the original Bart(Mike Lewis et al). The final goal is to achieve some \"good\" metrics on our custom dataset made up of EPFL's news over the five last years. Recently, large-scale pre-trained language models, such as BERT (Devlin et al., 2018) and GPT (Radford et al., 2018), have been used effectively as the base models for building task-specific natural language understanding (NLU) models via fine-tuning (such as text classification). However those pre-trained models are expensive to serve at runtime (e.g. BERT contains 24 transformer layers with 344 million parameters, and GPT-2 contains 48 transformer layers with 1.5 billion parameters), which make them impossible to deploy on devices such as mobile phones and medium size websites. That's how it comes to distillation and fine-tuning pre-trained model."})})]}),Object(h.jsxs)("div",{className:"section-wrapper",children:[Object(h.jsx)("div",{className:"title-wrapper",children:Object(h.jsx)("h4",{className:"content-padding-left-level4",children:"What is knowledge distillation ?"})}),Object(h.jsx)("div",{className:"content-wrapper",children:Object(h.jsx)("p",{children:"Knowledge distillation is a process of distilling or transferring the knowledge from a (set of) large, cumbersome model(s) to a lighter, easier-to-deploy single model, without significant loss in performance (Hinton et al., 2015). This small model will be able to produce comparable results, and in some cases, it can even be made capable of replicating the results of the cumbersome model. We consider the cumbersome model as Teacher Network and our new small model as Student Network."})})]}),Object(h.jsxs)("div",{className:"section-wrapper",children:[Object(h.jsx)("div",{className:"title-wrapper",children:Object(h.jsx)("h4",{className:"content-padding-left-level4",children:"Model size and metrics "})}),Object(h.jsxs)("div",{className:"content-wrapper",children:[Object(h.jsxs)("p",{children:["The model we use is from the distillation from of the original BART over the CNN/Daily mail summarization dataset. It is provided by the HuggingFace API via the ",Object(h.jsx)("code",{children:"transformers"})," package."]}),Object(h.jsxs)("table",{children:[Object(h.jsx)("caption",{children:"Table 1.1 Model parameters"}),Object(h.jsxs)("tr",{children:[Object(h.jsx)("th",{children:"Model name"}),Object(h.jsx)("th",{children:" # of parameters"}),Object(h.jsx)("th",{children:"Rouge 2"}),Object(h.jsx)("th",{children:"Rouge L"}),Object(h.jsx)("th",{children:"Speed up"})]}),Object(h.jsxs)("tr",{children:[Object(h.jsxs)("td",{children:["bart-large-cnn ",Object(h.jsx)("br",{}),"(baseline)"]}),Object(h.jsx)("td",{children:"406 M"}),Object(h.jsx)("td",{children:"21.06"}),Object(h.jsx)("td",{children:"30.63"}),Object(h.jsx)("td",{children:"1"})]}),Object(h.jsxs)("tr",{children:[Object(h.jsx)("td",{children:"distilbart-12-6-cnn"}),Object(h.jsx)("td",{children:"306 M"}),Object(h.jsx)("td",{children:"21.26"}),Object(h.jsx)("td",{children:"30.59"}),Object(h.jsx)("td",{children:"1.24"})]})]})]})]}),Object(h.jsxs)("div",{id:"dataset-wrapper",className:"section-wrapper",children:[Object(h.jsx)("div",{className:"title-wrapper",children:Object(h.jsx)("h4",{className:"content-padding-left-level4",children:"News Corpus"})}),Object(h.jsxs)("div",{className:"content-wrapper",children:[Object(h.jsx)("p",{children:" The dataset is made up of 1533 newspapers and their gold summaries i.e produced by human expert. We have split the dataset into two sets, one is the training set (80%) and the other is the test set (20%). Here is a link below to download the dataset (CSV format)."}),Object(h.jsx)(O,{href:"https://s3.eu-west-3.amazonaws.com/summarization.data.io/news-large-1.zip",className:"button-link border-radius-wrapper","data-type":"download",children:"Download the dataset (2.7 MO)"})]})]}),Object(h.jsxs)("div",{className:"section-wrapper",children:[Object(h.jsx)("div",{className:"title-wrapper",children:Object(h.jsx)("h4",{className:"content-padding-left-level4",children:"Getting started"})}),Object(h.jsxs)("div",{className:"content-wrapper",children:[Object(h.jsxs)("p",{children:["Download the model last checkpoint from the link below. It can be loaded from native PyTorch or via the",Object(h.jsx)("code",{children:"transformers"})," library"]}),Object(h.jsx)(O,{href:"https://s3.eu-west-3.amazonaws.com/summarization.data.io/model-2-en.zip",className:"button-link border-radius-wrapper","data-type":"download",children:"Download the model (1.2 GB)"}),Object(h.jsx)("p",{children:"Download the python notebook to load the model. The notebook provided to run within a GPU environment (Kaggle, Colab, etc.)"}),Object(h.jsx)(O,{href:"",className:"button-link border-radius-wrapper","data-type":"download",children:"Download the notebook"})]})]}),Object(h.jsxs)("div",{className:"section-wrapper",children:[Object(h.jsx)("div",{className:"title-wrapper",children:Object(h.jsx)("h4",{className:"content-padding-left-level4",children:"Preliminary results"})}),Object(h.jsxs)("div",{className:"content-wrapper",children:[Object(h.jsxs)("p",{children:["The model is fine-tuned in Kaggle's environment (1GPU P100-16GB) with a batch size of 2 over 20 epochs. We used Adam optimizer with l",Object(h.jsx)("sub",{children:"r"})," = 5x10",Object(h.jsx)("sup",{children:"-5"})," and settled a linear 6% warmup steps. Additionally, the news were cleaned from any HTML tag since the original CNN dataset is clean text."]}),Object(h.jsxs)("table",{children:[Object(h.jsx)("caption",{children:"Table 1.2 Metrics of the fine-tuned model"}),Object(h.jsxs)("tr",{children:[Object(h.jsx)("th",{children:"Metrics"}),Object(h.jsxs)("th",{children:["distilbart-12-6-cnn ",Object(h.jsx)("br",{}),"(base)"]}),Object(h.jsxs)("th",{children:["distilbart-12-6-cnn ",Object(h.jsx)("br",{})," (fine-tuned)"]})]}),Object(h.jsxs)("tr",{children:[Object(h.jsx)("td",{children:"Rouge 1"}),Object(h.jsx)("td",{children:"35.69"}),Object(h.jsx)("td",{children:"44.90"})]}),Object(h.jsxs)("tr",{children:[Object(h.jsx)("td",{children:"Rouge 2"}),Object(h.jsx)("td",{children:"10.80"}),Object(h.jsx)("td",{children:"16.01"})]}),Object(h.jsxs)("tr",{children:[Object(h.jsx)("td",{children:"Rouge L"}),Object(h.jsx)("td",{children:"23.71"}),Object(h.jsx)("td",{children:"32.65"})]})]})]})]})]})})}}]),n}(a.a.Component),x=n(15);n(51);function v(e){return Object(h.jsxs)("div",{className:"article-wrapper",children:[Object(h.jsx)("h4",{className:"article-title",children:e.title}),Object(h.jsx)("div",{className:"article-content",dangerouslySetInnerHTML:{__html:e.content}}),Object(h.jsx)("div",{className:"article-token-count",children:Object(h.jsxs)("span",{className:"token-count-value",children:["Number of tokens: ",e.numberOfTokens]})})]})}n(52),n(53);var f=function(e){Object(o.a)(n,e);var t=Object(d.a)(n);function n(){return Object(r.a)(this,n),t.apply(this,arguments)}return Object(l.a)(n,[{key:"render",value:function(){return Object(h.jsxs)("div",{className:"metric-container",children:[Object(h.jsx)("div",{className:"metric-bar-container",children:Object(h.jsx)("div",{className:"metric-bar",style:{backgroundColor:this.props.color,width:this.props.value+"%"}})}),Object(h.jsxs)("div",{className:"metric-span",children:[Object(h.jsxs)("span",{className:"metric-name",children:[" ",this.props.name,": "]}),Object(h.jsxs)("span",{className:"metric-value",children:[this.props.value," %"]})]})]})}}]),n}(a.a.Component);f.defaultProps={color:"royalblue"};var g=n(33),w=n.n(g);n(73);function N(e){return Object(h.jsxs)("div",{className:"summary-container",children:[Object(h.jsx)("h5",{className:"summary-type",children:e.type}),Object(h.jsx)("span",{className:"summary-content",dangerouslySetInnerHTML:{__html:e.content}})]})}var y=function(e){Object(o.a)(n,e);var t=Object(d.a)(n);function n(e){var s;return Object(r.a)(this,n),s=t.call(this,e),document.title="Generated summaries",s.state={dataLoaded:!1,data:null,loadingFailed:!1,currentItemIndex:null,totalItemCount:null,isLoading:!1,currentItem:void 0},s.loadData=s.loadData.bind(Object(x.a)(s)),s.selectItem=s.selectItem.bind(Object(x.a)(s)),s}return Object(l.a)(n,[{key:"componentDidMount",value:function(){this.loadData()}},{key:"selectItem",value:function(e){try{var t=this.state.totalItemCount,n=(e%t+t)%t;this.setState({currentItemIndex:n,currentItem:this.state.data[n]})}catch(s){console.error(s)}}},{key:"loadData",value:function(){var e=this;this.setState({isLoading:!0}),w.a.get("/data.json").then((function(t){var n=t.data;e.setState({data:n,dataLoaded:!0,currentItemIndex:0,totalItemCount:Object.keys(n).length,currentItem:n[0]}),console.log(e.state)})).catch((function(t){console.log("error occurred"+t),e.setState({loadingFailed:!0})})).finally((function(){e.setState({isLoading:!1})}))}},{key:"render",value:function(){var e=this,t=this.state.currentItem;return Object(h.jsxs)("div",{className:"document-viewer-container",children:[Object(h.jsx)("div",{className:"document-viewer-overlay",children:this.state.isLoading&&Object(h.jsx)("div",{className:"loader-container"})}),this.state.dataLoaded&&Object(h.jsxs)(h.Fragment,{children:[Object(h.jsxs)("div",{className:"controls-section",children:[Object(h.jsx)("button",{onClick:function(){e.selectItem(e.state.currentItemIndex-1)},children:"Previous"}),Object(h.jsx)("button",{onClick:function(){e.selectItem(e.state.currentItemIndex+1)},children:"Next"})]}),Object(h.jsx)("div",{className:"article-section content-section",children:Object(h.jsx)(v,{title:t.title,content:t.document,numberOfTokens:t.num_tokens})}),Object(h.jsxs)("div",{className:"summaries-section content-section",children:[Object(h.jsx)(N,{type:"Human reference summary",content:t.reference_summary}),Object(h.jsx)(N,{type:"DistillBart base model summary",content:t.base_model_summary}),Object(h.jsx)(f,{value:t.rouge1bm,name:"ROUGE 1"}),Object(h.jsx)(f,{value:t.rouge2bm,name:"ROUGE 2"}),Object(h.jsx)(f,{value:t.rougeLbm,name:"ROUGE L"}),Object(h.jsx)(N,{type:"Our fine-tuned DistillBart model summary",content:t.fine_tuned_model_summary}),Object(h.jsx)(f,{value:t.rouge1ft,name:"ROUGE 1"}),Object(h.jsx)(f,{value:t.rouge2ft,name:"ROUGE 2"}),Object(h.jsx)(f,{value:t.rougeLft,name:"ROUGE L"})]}),Object(h.jsx)("div",{className:"metrics-description",children:"*ROUGE higher is better"})]})]})}}]),n}(a.a.Component),k=(n(74),function(e){Object(o.a)(n,e);var t=Object(d.a)(n);function n(){return Object(r.a)(this,n),t.apply(this,arguments)}return Object(l.a)(n,[{key:"render",value:function(){return Object(h.jsx)("div",{className:"content-container",children:this.props.children})}}]),n}(a.a.Component)),I=n(2);var L=function(){return Object(h.jsxs)("div",{className:"App",children:[Object(h.jsxs)(j.a,{children:[" ",Object(h.jsx)(m,{}),Object(h.jsx)(k,{children:Object(h.jsxs)(I.c,{children:[Object(h.jsx)(I.a,{exact:!0,path:"/",component:p}),Object(h.jsx)(I.a,{exact:!0,path:"/home",component:p}),Object(h.jsx)(I.a,{exact:!0,path:"/example",component:y}),Object(h.jsx)(I.a,{children:Object(h.jsx)("h1",{children:"Not found"})})]})})]}),Object(h.jsx)(b,{})]})},T=function(e){e&&e instanceof Function&&n.e(3).then(n.bind(null,76)).then((function(t){var n=t.getCLS,s=t.getFID,a=t.getFCP,c=t.getLCP,i=t.getTTFB;n(e),s(e),a(e),c(e),i(e)}))};i.a.render(Object(h.jsx)(a.a.StrictMode,{children:Object(h.jsx)(L,{})}),document.getElementById("root")),T()}},[[75,1,2]]]);
//# sourceMappingURL=main.1969eae9.chunk.js.map